{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMQa526p7C2equ+rvGCL8Xv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bismuthe-32/Adaptive-Basis-Functions-for-Enhanced-Kolmogorov/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adaptive Basis Functions in Kolmogorov Arnold Networks\n",
        "\n",
        "This paper proposes adaptive basis functions (ABFs) for Kolmogorovâ€“Arnold Networks (KANs), enabling dynamic adjustment of univariate basis functions during training. ABF-KANs achieve smoother convergence, improved generalization, and reduced mean-squared error on noisy oscillatory and polynomial functions. Results indicate a 7.6\\% reduction in test error relative to fixed-basis KANs. The method addresses limitations of static basis functions, improving scalability, flexibility, and applicability of KANs in complex function approximation tasks."
      ],
      "metadata": {
        "id": "v8tqYwgaRIi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTv0xej_RC0c",
        "outputId": "e6b0dfde-0eaa-4f95-9f43-08d4dc2c6657"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.11.12)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "txpucT6_SXiT"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the following datasets:\n",
        "\n",
        "- **Synthetic Polynomial Functions:** Functions of the form  \n",
        "\n",
        "  $$\n",
        "  f(x) = \\sum_{i=0}^{d} p_i x^i + \\epsilon\n",
        "  $$\n",
        "\n",
        "  where each polynomial coefficient $p_i$ is sampled from a standard Gaussian distribution, and $\\epsilon$ represents additive noise. The domain is $x \\in [0,10]$, and the output is normalized to the range $[0,1]$.  \n",
        "\n",
        "- **Boston Housing:** Predicts house prices using 13 input features.  \n",
        "\n",
        "- **Airfoil Self-Noise:** Predicts sound pressure levels from 5 aerodynamic input variables.  \n",
        "\n",
        "- **Energy Efficiency:** Predicts heating and cooling loads from 8 building characteristics.  \n",
        "\n",
        "All datasets are standardized to zero mean and unit variance.\n"
      ],
      "metadata": {
        "id": "EJHtTXntRTjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_poly_function(degrees=3, num_points=100, noise_std=0.0):\n",
        "  X = torch.linspace(0,11,num_points)\n",
        "  pis = torch.randn(degrees+1,1)\n",
        "\n",
        "  y = sum(pis[i] * X**i for i in range(degrees + 1))\n",
        "\n",
        "  if noise_std > 0:\n",
        "    y += torch.randn_like(y) * noise_std\n",
        "\n",
        "  return X,y\n"
      ],
      "metadata": {
        "id": "DK5UIOgHMIjS"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def boston():\n",
        "      data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "      raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "      return raw_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1bO-a-bQ6pX",
        "outputId": "987c433e-660a-4580-9ad1-a64db2915178"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-2922621118.py:3: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def airfoil_selfnoise():\n",
        "  URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat'\n",
        "  columns = ['frequency',\n",
        "            'angle_of_attack',\n",
        "            'chord_length',\n",
        "            'free_stream_velocity',\n",
        "            'suction_side_displacement_thickness',\n",
        "            'scaled_sound_pressure_level']\n",
        "\n",
        "  features = ['frequency','angle_of_attack',\n",
        "              'chord_length',\n",
        "              'free_stream_velocity',\n",
        "              'suction_side_displacement_thickness']\n",
        "\n",
        "  airfoil_dataset = pd.read_csv(url_file, sep='\\t', header=None, names=columns)"
      ],
      "metadata": {
        "id": "roGBmxjWOH62"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def energy_efficiency():\n",
        "  return fetch_ucirepo(id=242)"
      ],
      "metadata": {
        "id": "ZqroJmVqQeok"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architectures\n",
        "\n",
        "We compare Adaptive KANs to three other models:\n",
        "\n",
        "**Fourier Feature Networks** : Fourier Feature Networks use a Fourier Feature Mapping to transform low-dimensional inputs (like pixel coordinates) into a higher-dimensional space using sines and cosines, allowing standard Multi-Layer Perceptrons (MLPs) to efficiently learn complex, high-frequency functions\n",
        "\n",
        "**Multilayer Percpetron (MLPs)**: Multi-Layer Perceptrons (MLPs) are fundamental, fully connected feedforward neural networks with input, hidden, and output layers, using non-linear activation functions (like ReLU or sigmoid) to learn complex, non-linear patterns in structured data\n",
        "\n",
        "**KANs with fixed basis functions** : Kolmogorov-Arnold Networks (KANs) are a novel neural network architecture that replaces fixed node activations in traditional Multi-Layer Perceptrons (MLPs) with learnable, univariate functions (splines) on the network's edges, offering enhanced accuracy, interpretability, and efficiency for complex function approximation"
      ],
      "metadata": {
        "id": "w761wvGMSWPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Many thanks to Professor Matthew Johnson at University of Cambridge Department of Engineering for providing the PyTorch Network of Fourier Feature Networks. Full repository on FFNs can be found [here](https://github.com/matajoh/fourier_feature_nets)"
      ],
      "metadata": {
        "id": "JSUDMzcrVw-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, List\n",
        "\n",
        "class FourierFeatureMLP(nn.Module):\n",
        "    \"\"\"MLP using Fourier features as a preprocessing step.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_inputs: int,\n",
        "                 num_outputs: int,\n",
        "                 a_values: Optional[torch.Tensor],\n",
        "                 b_values: Optional[torch.Tensor],\n",
        "                 layer_channels: List[int]):\n",
        "        super().__init__()\n",
        "        self.num_inputs = num_inputs\n",
        "\n",
        "        # Fourier feature encoding\n",
        "        if b_values is None:\n",
        "            self.a_values = None\n",
        "            self.b_values = None\n",
        "            encoded_inputs = num_inputs\n",
        "        else:\n",
        "            assert b_values.shape[0] == num_inputs, \"b_values first dim must match num_inputs\"\n",
        "            assert a_values.shape[0] == b_values.shape[1], \"a_values shape mismatch\"\n",
        "            self.a_values = nn.Parameter(a_values, requires_grad=False)\n",
        "            self.b_values = nn.Parameter(b_values, requires_grad=False)\n",
        "            encoded_inputs = b_values.shape[1] * 2\n",
        "\n",
        "        # Store params for reproducibility\n",
        "        self.params = {\n",
        "            \"num_inputs\": num_inputs,\n",
        "            \"num_outputs\": num_outputs,\n",
        "            \"a_values\": None if a_values is None else a_values.tolist(),\n",
        "            \"b_values\": None if b_values is None else b_values.tolist(),\n",
        "            \"layer_channels\": layer_channels\n",
        "        }\n",
        "\n",
        "        # Build MLP layers\n",
        "        self.layers = nn.ModuleList()\n",
        "        for num_channels in layer_channels:\n",
        "            self.layers.append(nn.Linear(encoded_inputs, num_channels))\n",
        "            encoded_inputs = num_channels\n",
        "        self.layers.append(nn.Linear(encoded_inputs, num_outputs))\n",
        "\n",
        "        # Activation tracking\n",
        "        self.keep_activations = False\n",
        "        self.activations: List = []\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self.b_values is not None:\n",
        "            encoded = math.pi * x @ self.b_values\n",
        "            x = torch.cat([self.a_values * encoded.cos(),\n",
        "                           self.a_values * encoded.sin()], dim=-1)\n",
        "\n",
        "        self.activations.clear()\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = torch.relu(layer(x))\n",
        "        if self.keep_activations:\n",
        "            self.activations.append(x.detach().cpu().numpy())\n",
        "        x = self.layers[-1](x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "5czhjHB2SQkv"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP\n",
        "\n",
        "We use an MLP with only one hidden layer, and a ReLU activation"
      ],
      "metadata": {
        "id": "_4enUD62WWwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        # Define the layers\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # Fully connected layer 1\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size) # Fully connected layer 2\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define the forward pass\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "xnTHxdaBV_2-"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KAN with fixed basis functions\n",
        "\n",
        "The network below comprises of a Kolmogorov Arnold network with fixed basis functions. Many thanks to Blealtan for creating the following code snippet. Full repository can be found [here](https://github.com/Blealtan/efficient-kan/tree/master)"
      ],
      "metadata": {
        "id": "SpJIBAemXRW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "\n",
        "class KANLinear(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features,\n",
        "        out_features,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        enable_standalone_scale_spline=True,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KANLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        h = (grid_range[1] - grid_range[0]) / grid_size\n",
        "        grid = (\n",
        "            (\n",
        "                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n",
        "                + grid_range[0]\n",
        "            )\n",
        "            .expand(in_features, -1)\n",
        "            .contiguous()\n",
        "        )\n",
        "        self.register_buffer(\"grid\", grid)\n",
        "\n",
        "        self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.spline_weight = torch.nn.Parameter(\n",
        "            torch.Tensor(out_features, in_features, grid_size + spline_order)\n",
        "        )\n",
        "        if enable_standalone_scale_spline:\n",
        "            self.spline_scaler = torch.nn.Parameter(\n",
        "                torch.Tensor(out_features, in_features)\n",
        "            )\n",
        "\n",
        "        self.scale_noise = scale_noise\n",
        "        self.scale_base = scale_base\n",
        "        self.scale_spline = scale_spline\n",
        "        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n",
        "        self.base_activation = base_activation()\n",
        "        self.grid_eps = grid_eps\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n",
        "        with torch.no_grad():\n",
        "            noise = (\n",
        "                (\n",
        "                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n",
        "                    - 1 / 2\n",
        "                )\n",
        "                * self.scale_noise\n",
        "                / self.grid_size\n",
        "            )\n",
        "            self.spline_weight.data.copy_(\n",
        "                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n",
        "                * self.curve2coeff(\n",
        "                    self.grid.T[self.spline_order : -self.spline_order],\n",
        "                    noise,\n",
        "                )\n",
        "            )\n",
        "            if self.enable_standalone_scale_spline:\n",
        "                # torch.nn.init.constant_(self.spline_scaler, self.scale_spline)\n",
        "                torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n",
        "\n",
        "    def b_splines(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the B-spline bases for the given input tensor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: B-spline bases tensor of shape (batch_size, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "\n",
        "        grid: torch.Tensor = (\n",
        "            self.grid\n",
        "        )  # (in_features, grid_size + 2 * spline_order + 1)\n",
        "        x = x.unsqueeze(-1)\n",
        "        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
        "        for k in range(1, self.spline_order + 1):\n",
        "            bases = (\n",
        "                (x - grid[:, : -(k + 1)])\n",
        "                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n",
        "                * bases[:, :, :-1]\n",
        "            ) + (\n",
        "                (grid[:, k + 1 :] - x)\n",
        "                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n",
        "                * bases[:, :, 1:]\n",
        "            )\n",
        "\n",
        "        assert bases.size() == (\n",
        "            x.size(0),\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return bases.contiguous()\n",
        "\n",
        "    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the coefficients of the curve that interpolates the given points.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "            y (torch.Tensor): Output tensor of shape (batch_size, in_features, out_features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Coefficients tensor of shape (out_features, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        assert y.size() == (x.size(0), self.in_features, self.out_features)\n",
        "\n",
        "        A = self.b_splines(x).transpose(\n",
        "            0, 1\n",
        "        )  # (in_features, batch_size, grid_size + spline_order)\n",
        "        B = y.transpose(0, 1)  # (in_features, batch_size, out_features)\n",
        "        solution = torch.linalg.lstsq(\n",
        "            A, B\n",
        "        ).solution  # (in_features, grid_size + spline_order, out_features)\n",
        "        result = solution.permute(\n",
        "            2, 0, 1\n",
        "        )  # (out_features, in_features, grid_size + spline_order)\n",
        "\n",
        "        assert result.size() == (\n",
        "            self.out_features,\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return result.contiguous()\n",
        "\n",
        "    @property\n",
        "    def scaled_spline_weight(self):\n",
        "        return self.spline_weight * (\n",
        "            self.spline_scaler.unsqueeze(-1)\n",
        "            if self.enable_standalone_scale_spline\n",
        "            else 1.0\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        assert x.size(-1) == self.in_features\n",
        "        original_shape = x.shape\n",
        "        x = x.reshape(-1, self.in_features)\n",
        "\n",
        "        base_output = F.linear(self.base_activation(x), self.base_weight)\n",
        "        spline_output = F.linear(\n",
        "            self.b_splines(x).view(x.size(0), -1),\n",
        "            self.scaled_spline_weight.view(self.out_features, -1),\n",
        "        )\n",
        "        output = base_output + spline_output\n",
        "\n",
        "        output = output.reshape(*original_shape[:-1], self.out_features)\n",
        "        return output\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_grid(self, x: torch.Tensor, margin=0.01):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        batch = x.size(0)\n",
        "\n",
        "        splines = self.b_splines(x)  # (batch, in, coeff)\n",
        "        splines = splines.permute(1, 0, 2)  # (in, batch, coeff)\n",
        "        orig_coeff = self.scaled_spline_weight  # (out, in, coeff)\n",
        "        orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)\n",
        "        unreduced_spline_output = torch.bmm(splines, orig_coeff)  # (in, batch, out)\n",
        "        unreduced_spline_output = unreduced_spline_output.permute(\n",
        "            1, 0, 2\n",
        "        )  # (batch, in, out)\n",
        "\n",
        "        # sort each channel individually to collect data distribution\n",
        "        x_sorted = torch.sort(x, dim=0)[0]\n",
        "        grid_adaptive = x_sorted[\n",
        "            torch.linspace(\n",
        "                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n",
        "        grid_uniform = (\n",
        "            torch.arange(\n",
        "                self.grid_size + 1, dtype=torch.float32, device=x.device\n",
        "            ).unsqueeze(1)\n",
        "            * uniform_step\n",
        "            + x_sorted[0]\n",
        "            - margin\n",
        "        )\n",
        "\n",
        "        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
        "        grid = torch.concatenate(\n",
        "            [\n",
        "                grid[:1]\n",
        "                - uniform_step\n",
        "                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n",
        "                grid,\n",
        "                grid[-1:]\n",
        "                + uniform_step\n",
        "                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        self.grid.copy_(grid.T)\n",
        "        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        \"\"\"\n",
        "        Compute the regularization loss.\n",
        "\n",
        "        This is a dumb simulation of the original L1 regularization as stated in the\n",
        "        paper, since the original one requires computing absolutes and entropy from the\n",
        "        expanded (batch, in_features, out_features) intermediate tensor, which is hidden\n",
        "        behind the F.linear function if we want an memory efficient implementation.\n",
        "\n",
        "        The L1 regularization is now computed as mean absolute value of the spline\n",
        "        weights. The authors implementation also includes this term in addition to the\n",
        "        sample-based regularization.\n",
        "        \"\"\"\n",
        "        l1_fake = self.spline_weight.abs().mean(-1)\n",
        "        regularization_loss_activation = l1_fake.sum()\n",
        "        p = l1_fake / regularization_loss_activation\n",
        "        regularization_loss_entropy = -torch.sum(p * p.log())\n",
        "        return (\n",
        "            regularize_activation * regularization_loss_activation\n",
        "            + regularize_entropy * regularization_loss_entropy\n",
        "        )\n",
        "\n",
        "\n",
        "class KAN(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        layers_hidden,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KAN, self).__init__()\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n",
        "            self.layers.append(\n",
        "                KANLinear(\n",
        "                    in_features,\n",
        "                    out_features,\n",
        "                    grid_size=grid_size,\n",
        "                    spline_order=spline_order,\n",
        "                    scale_noise=scale_noise,\n",
        "                    scale_base=scale_base,\n",
        "                    scale_spline=scale_spline,\n",
        "                    base_activation=base_activation,\n",
        "                    grid_eps=grid_eps,\n",
        "                    grid_range=grid_range,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, update_grid=False):\n",
        "        for layer in self.layers:\n",
        "            if update_grid:\n",
        "                layer.update_grid(x)\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        return sum(\n",
        "            layer.regularization_loss(regularize_activation, regularize_entropy)\n",
        "            for layer in self.layers\n",
        "        )"
      ],
      "metadata": {
        "id": "lxdO2a69WsBe"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaptiveKAN(KAN):\n",
        "    \"\"\"\n",
        "    KAN with adaptive basis functions.\n",
        "    Automatically updates the spline grid based on input distribution\n",
        "    at each forward pass if `update_grid=True`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        layers_hidden,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "        update_grid_every_forward=True,  # controls auto adaptation\n",
        "    ):\n",
        "        super().__init__(\n",
        "            layers_hidden,\n",
        "            grid_size=grid_size,\n",
        "            spline_order=spline_order,\n",
        "            scale_noise=scale_noise,\n",
        "            scale_base=scale_base,\n",
        "            scale_spline=scale_spline,\n",
        "            base_activation=base_activation,\n",
        "            grid_eps=grid_eps,\n",
        "            grid_range=grid_range,\n",
        "        )\n",
        "        self.update_grid_every_forward = update_grid_every_forward\n",
        "\n",
        "    def forward(self, x: torch.Tensor, update_grid=False):\n",
        "        # If adaptive updating is enabled globally\n",
        "        adaptive_update = self.update_grid_every_forward or update_grid\n",
        "        for layer in self.layers:\n",
        "            if adaptive_update:\n",
        "                layer.update_grid(x)\n",
        "            x = layer(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "m86w2EkcYDnC"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6N9aEoxvYP-V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}